{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANN Network** \n",
    "                \n",
    "             Forward propagation: \n",
    "             input--2 hidden--10 , output--1\n",
    "\n",
    "| Input  |  ->   | LINEAR |  ->   | RELU |  ->   | LINEAR |  ->   | SIGMOID|\n",
    "|------  |------ |------  |------ |------|------ |------  |------ |------  |\n",
    "| 2      |  ->   | 10     |  ->   | 10   |  ->   | 1      |  ->   | 1      |\n",
    "\n",
    "\n",
    "*Input dimention* : format matrix, Row  are Number of  features and Columns is total number of input \n",
    "\n",
    "*cost function*:: Cross-entropy cost\n",
    "* Network can be apply for any binary  classification  problem \n",
    "\n",
    "* Only two layer are available \n",
    "\n",
    "**parameters**\n",
    "\n",
    "    dict_keys(['W1', 'b1', 'W2', 'b2']), [20, 10, 10, 1]\n",
    "    Total =41 (Trainble parameters)\n",
    "####  After  40000 Iteration Error Is Approx Zero (0.0119) \n",
    "\n",
    "\n",
    "**Output**\n",
    "\n",
    "     [0.00785878 0.9924926  0.99010905 0.01446849]\n",
    "\n",
    "#### After Only 500 Iteration network can classify correctly  100% accuracy\n",
    "\n",
    "**Output**\n",
    "\n",
    "     [0.49999978 0.50000008 0.50000014 0.49999993]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input type <class 'numpy.ndarray'>\n",
      "y_train size : (1, 4)\n",
      "x_train size : (2, 4)\n"
     ]
    }
   ],
   "source": [
    "x_train=np.array([[0.9,0.9],[0.9,0.1],[0.1,0.9],[0.1,0.1],]).T\n",
    "y_train=np.array([0,1,1,0]).reshape(1,-1)\n",
    "layers_dims = (2,10, 1) # input 2 units hideen  10 units one output unit.\n",
    "print(\"input type {}\".format(type(x_train)))\n",
    "print(\"y_train size : {}\".format(y_train.shape))\n",
    "print(\"x_train size : {}\".format(x_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(Z):\n",
    "    \n",
    "    return 1/(1+np.exp(-Z)), Z\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z), Z\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[cache <= 0] = 0\n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Intialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_n_layes(layer_dims):\n",
    "    parameters = {}\n",
    "    N = len(layer_dims)            # number of layers in the network\n",
    "    \n",
    "    \n",
    "    # intialized parameters layer by layer\n",
    "    for n in range(1, N):\n",
    "        parameters['W' + str(n)] = np.random.randn(layer_dims[n], layer_dims[n-1]) * 0.001\n",
    "        parameters['b' + str(n)] = np.zeros((layer_dims[n], 1))*0.001\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward propagation\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "    A -- After activations function apply \n",
    "    W -- weights matrix:\n",
    "    b -- bias \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    Z = np.dot(W,A)+ b \n",
    "    cache = (A, W, b)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        \n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 5000):\n",
    "    grads = {}\n",
    "    costs = []                              # to keep track of the cost \n",
    "    m = X.shape[1]                           # number of examples\n",
    "    \n",
    "    # Initialize parameters dictionary\n",
    "    parameters = initialize_parameters_n_layes(layers_dims)\n",
    "    \n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID.\n",
    "        A1, cache1 = linear_activation_forward(X, parameters[\"W1\"], parameters[\"b1\"], \"relu\")\n",
    "        A2, cache2 = linear_activation_forward(A1, parameters[\"W2\"], parameters[\"b2\"], \"sigmoid\")\n",
    "       \n",
    "        # Compute cost \n",
    "        cost = compute_cost(A2, Y)\n",
    "        \n",
    "        # Initializing backward propagation\n",
    "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
    "        \n",
    "        \n",
    "        # Backward propagation. \n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, \"sigmoid\")\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, \"relu\")\n",
    "        \n",
    "        # Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2\n",
    "        grads['dW1'],grads['db1'],grads['dW2'],grads['db2']  = dW1, db1, dW2, db2\n",
    "        \n",
    "        # Update parameters W1, b1, W2, b2\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "\n",
    "    \n",
    "        # Print the cost \n",
    "        step=2000 # store after step iterations\n",
    "        if i % step == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if i % step == 0:\n",
    "            costs.append(cost)\n",
    "       \n",
    "    # plot the cost\n",
    "\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations ({})'.format(step))\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    # return updated paramenters\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Arguments:\n",
    "    AL -- probability \n",
    "    Y -- true \"label\" \n",
    "    cost -- cross-entropy cost\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    cost = -1/m * np.sum(np.multiply(np.log(AL), Y) + np.multiply(1 - Y, np.log(1 - AL)))\n",
    "    \n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW =  1/m * np.dot(dZ, A_prev.T)\n",
    "    db = 1/m * np.sum(dZ,axis = 1,keepdims = True )\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    dZ -- Gradient with respect to ;\n",
    "    cache -- tuple of values (A_prev, W, b) from forward propagation\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with prev layer\n",
    "    dW -- db  Gradient\n",
    "    \"\"\"\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    #Gradient with respect to prev and Gradient\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \n",
    "    N = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update prameters W1,W2,b1,b2\n",
    "    for n in range(N):\n",
    "        parameters[\"W\" + str(n+1)] = parameters[\"W\" + str(n+1)] - learning_rate * grads[\"dW\" + str(n+1)]\n",
    "        parameters[\"b\" + str(n+1)] = parameters[\"b\" + str(n+1)] - learning_rate * grads[\"db\" + str(n+1)]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6931472586503031\n",
      "Cost after iteration 2000: 0.08488040170255441\n",
      "Cost after iteration 4000: 0.043621619253829416\n",
      "Cost after iteration 6000: 0.028393621517264545\n",
      "Cost after iteration 8000: 0.020795304140719912\n",
      "Cost after iteration 10000: 0.01631664160580837\n",
      "Cost after iteration 12000: 0.013398757810594113\n",
      "Cost after iteration 14000: 0.0113277506818646\n",
      "Cost after iteration 16000: 0.009804402003373798\n",
      "Cost after iteration 18000: 0.00863793300464562\n",
      "Cost after iteration 20000: 0.007716851584346558\n",
      "Cost after iteration 22000: 0.006971630803673124\n",
      "Cost after iteration 24000: 0.0063566453700167865\n",
      "Cost after iteration 26000: 0.0058369756719609004\n",
      "Cost after iteration 28000: 0.005395697278953169\n",
      "Cost after iteration 30000: 0.005015713871905336\n",
      "Cost after iteration 32000: 0.004685747739290655\n",
      "Cost after iteration 34000: 0.004394208190113125\n",
      "Cost after iteration 36000: 0.004138257066356378\n",
      "Cost after iteration 38000: 0.003910576233381333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = two_layer_model(x_train,y_train,\n",
    "                             layers_dims = layers_dims,\n",
    "                             num_iterations = 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters,layers_dims):\n",
    "    m = X.shape[1] # number of inputes\n",
    "    predictions = np.zeros((1,m)) # class\n",
    "    \n",
    "    # Forward propagation\n",
    "    A1, cache1 = linear_activation_forward(X, parameters['W1'], parameters['b1'], \"relu\")\n",
    "    A2, cache2 = linear_activation_forward(A1, parameters['W2'], parameters['b2'], \"sigmoid\")\n",
    "    print(A2)\n",
    "    \n",
    "    for i in range(A2.shape[1]):\n",
    "        if A2[:,i]>0.5:\n",
    "            predictions[:,i]=1\n",
    "        else:\n",
    "            predictions[:,i]=0\n",
    "    \n",
    "    print(\"Accuracy: \"  + str(np.sum((predictions == y)/m)))\n",
    "        \n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.58033964e-45 9.85648125e-01 9.99979495e-01 3.43721225e-04]]\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(x_train, y_train,parameters,layers_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['W1', 'b1', 'W2', 'b2']), [20, 10, 10, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters.keys(), [parameters[x].shape[0]*parameters[x].shape[1] for x in parameters.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
